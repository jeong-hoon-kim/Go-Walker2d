import gymnasium as gym
from gymnasium import Wrapper
from stable_baselines3 import PPO
from stable_baselines3.common.utils import set_random_seed
from gymnasium.wrappers import RecordVideo
import numpy as np
import os

# --- ì¤‘ìš”: í›ˆë ¨ ì‹œ ì‚¬ìš©í–ˆë˜ ì»¤ìŠ¤í…€ ë˜í¼ë¥¼ ì—¬ê¸°ì— ë˜‘ê°™ì´ ì •ì˜í•´ì•¼ í•©ë‹ˆë‹¤. ---
class GaitRewardWrapper(Wrapper):
    def __init__(self, env):
        super().__init__(env)
        self.time_step = 0
        
        # --- ê±¸ìŒê±¸ì´ íŒ¨í„´ì„ ìœ„í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ---
        # ì´ ê°’ë“¤ì„ ì¡°ì •í•˜ë©° ìµœì ì˜ ê±¸ìŒê±¸ì´ë¥¼ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤.
        self.gait_frequency = 2.5  # ê±¸ìŒê±¸ì´ ì†ë„ (Hz)
        self.hip_amplitude = 0.5   # í—ˆë²…ì§€ ê´€ì ˆì˜ ì›€ì§ì„ í­ (radian)
        self.knee_amplitude = 0.5  # ë¬´ë¦ ê´€ì ˆì˜ ì›€ì§ì„ í­ (radian)
        self.gait_reward_weight = 0.2 # íŒ¨í„´ ë³´ìƒì˜ ê°€ì¤‘ì¹˜

    def reset(self, **kwargs):
        self.time_step = 0
        return self.env.reset(**kwargs)

    def step(self, action):
        obs, reward, terminated, truncated, info = self.env.step(action)
        self.time_step += self.env.unwrapped.dt # ì‹œë®¬ë ˆì´ì…˜ ì‹œê°„ ì—…ë°ì´íŠ¸

        # --- ğŸ† ê±¸ìŒê±¸ì´ íŒ¨í„´ ë³´ìƒ (Gait Pattern Reward) ---
        
        # 1. ì´ìƒì ì¸ ëª©í‘œ ê°ë„ë¥¼ ì‚¬ì¸íŒŒë¡œ ê³„ì‚°
        # í˜„ì¬ ì‹œê°„(t)ì„ ê¸°ë°˜ìœ¼ë¡œ ê° ê´€ì ˆì´ ê°€ì ¸ì•¼ í•  ì´ìƒì ì¸ ê°ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        phase = 2 * np.pi * self.gait_frequency * self.time_step
        
        # ì˜¤ë¥¸ìª½ ë‹¤ë¦¬ì˜ ëª©í‘œ ê°ë„
        target_right_hip_angle = self.hip_amplitude * np.sin(phase)
        target_right_knee_angle = self.knee_amplitude * np.sin(phase + np.pi / 2) # ë¬´ë¦ì€ ìœ„ìƒì´ ì•½ê°„ ë‹¤ë¦„
        
        # ì™¼ìª½ ë‹¤ë¦¬ëŠ” ì˜¤ë¥¸ìª½ê³¼ 180ë„(pi) ë°˜ëŒ€ ìœ„ìƒ
        target_left_hip_angle = self.hip_amplitude * np.sin(phase + np.pi)
        target_left_knee_angle = self.knee_amplitude * np.sin(phase + np.pi + np.pi / 2)

        # 2. ì‹¤ì œ ê´€ì ˆ ê°ë„ì™€ ëª©í‘œ ê°ë„ì˜ ì°¨ì´ ê³„ì‚°
        # obs ë²¡í„°ì—ì„œ ì‹¤ì œ ê´€ì ˆ ê°ë„ ê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        actual_right_hip_angle = obs[2]
        actual_right_knee_angle = obs[3] # ì¢…ì•„ë¦¬ ê´€ì ˆì´ ë¬´ë¦ ì—­í• 
        actual_left_hip_angle = obs[5]
        actual_left_knee_angle = obs[6]

        # 3. ì˜¤ì°¨ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í˜ë„í‹° ê³„ì‚° (ì˜¤ì°¨ê°€ ì‘ì„ìˆ˜ë¡ í˜ë„í‹°ê°€ ì ìŒ)
        hip_error = (actual_right_hip_angle - target_right_hip_angle)**2 + \
                    (actual_left_hip_angle - target_left_hip_angle)**2
        knee_error = (actual_right_knee_angle - target_right_knee_angle)**2 + \
                     (actual_left_knee_angle - target_left_knee_angle)**2
                     
        # ì˜¤ì°¨ê°€ í´ìˆ˜ë¡ í° í˜ë„í‹°ë¥¼ ë¶€ì—¬ (ë³´ìƒ = -ê°€ì¤‘ì¹˜ * ì˜¤ì°¨)
        gait_penalty = -self.gait_reward_weight * (hip_error + knee_error)

        # 4. ìµœì¢… ë³´ìƒì— í•©ì‚°
        new_reward = reward + gait_penalty
        
        return obs, new_reward, terminated, truncated, info

def test_model(model_path, seed, use_custom_wrapper, video_folder):

    print(f"--- '{model_path}' ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘ (ì‹œë“œ: {seed}) ---")

    # 1. í™˜ê²½ ìƒì„±
    env = gym.make("Walker2d-v5", render_mode="rgb_array")

    # 2. ë¹„ë””ì˜¤ ë…¹í™” ë˜í¼ ì ìš©
    os.makedirs(video_folder, exist_ok=True)
    model_name = os.path.splitext(os.path.basename(model_path))[0]
    video_prefix = f"test_{model_name}_seed{seed}"
    env = RecordVideo(env, video_folder=video_folder, name_prefix=video_prefix, fps=30)
    
    # --- ì¤‘ìš” ---
    if use_custom_wrapper:
        print("ê²½ê³ : í…ŒìŠ¤íŠ¸ í™˜ê²½ì— ì»¤ìŠ¤í…€ ë³´ìƒ ë˜í¼ë¥¼ ì ìš©í•©ë‹ˆë‹¤. 'ì´ ë³´ìƒ' ì ìˆ˜ê°€ í›ˆë ¨ ê¸°ì¤€ê³¼ ê°™ê²Œ ë©ë‹ˆë‹¤.")
        env = GaitRewardWrapper(env)

    # 4. í›ˆë ¨ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    set_random_seed(seed)
    model = PPO.load(model_path, env=env)

    # 5. í‰ê°€ ì‹œì‘
    obs, info = env.reset(seed=seed)
    
    # í‰ê°€ ì§€í‘œ ì´ˆê¸°í™”
    torso_angles = []
    total_reward = 0
    final_distance = 0
    done = False

    while not done:
        action, _ = model.predict(obs, deterministic=True)
        obs, reward, terminated, truncated, info = env.step(action)
        done = terminated or truncated

        # í‰ê°€ ì§€í‘œ ìˆ˜ì§‘
        torso_angle = obs[1]
        torso_angles.append(torso_angle)
        total_reward += reward
        
        if done:
            final_distance = info.get('x_position', 0)

    # 6. ìµœì¢… ê²°ê³¼ ê³„ì‚° ë° ì¶œë ¥
    stability_score = np.std(torso_angles)

    print("\n--- ìµœì¢… í‰ê°€ ê²°ê³¼ ---")
    print(f"ëª¨ë¸: {model_path}")
    print(f"ìµœì¢… ì´ë™ ê±°ë¦¬: {final_distance:.2f} m")
    print(f"ì´ ë³´ìƒ (í…ŒìŠ¤íŠ¸ í™˜ê²½ ê¸°ì¤€): {total_reward:.2f}")
    print(f"ëª¸í†µ í”ë“¤ë¦¼ (ì•ˆì •ì„±): {stability_score:.4f} (ë‚®ì„ìˆ˜ë¡ ì•ˆì •ì )")
    print(f"ì˜ìƒ ì €ì¥ ìœ„ì¹˜: {os.path.join(video_folder, video_prefix)}-video-0.mp4")
    print("-" * 30 + "\n")

    env.close()


if __name__ == "__main__":
    # --- í…ŒìŠ¤íŠ¸ ì„¤ì • ---
    MODEL_PATH = "results/ppo_walker2d_custom_reward_v1/best_distance_model.zip" 
    SEED = 42
    VIDEO_FOLDER = "videos_test_custom/"
    
    USE_CUSTOM_WRAPPER = False

    test_model(
        model_path=MODEL_PATH,
        seed=SEED,
        use_custom_wrapper=USE_CUSTOM_WRAPPER,
        video_folder=VIDEO_FOLDER
    )